{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ML Logo](http://spark-mooc.github.io/web-assets/images/CS190.1x_Banner_300.png)\n",
    "# **Linear Regression Lab**\n",
    "#### This lab covers a common supervised learning pipeline, using a subset of the [Million Song Dataset](http://labrosa.ee.columbia.edu/millionsong/) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD). Our goal is to train a linear regression model to predict the release year of a song given a set of audio features.\n",
    "#### ** This lab will cover: **\n",
    "+  ####*Part 1:* Read and parse the initial dataset\n",
    " + #### *Visualization 1:* Features\n",
    " + #### *Visualization 2:* Shifting labels\n",
    "+  ####*Part 2:* Create and evaluate a baseline model\n",
    " + #### *Visualization 3:* Predicted vs. actual\n",
    "+  ####*Part 3:* Train (via gradient descent) and evaluate a linear regression model\n",
    " + #### *Visualization 4:* Training error\n",
    "+  ####*Part 4:* Train using MLlib and tune hyperparameters via grid search\n",
    " + #### *Visualization 5:* Best model's predictions\n",
    " + #### *Visualization 6:* Hyperparameter heat map\n",
    "+  ####*Part 5:* Add interactions between features\n",
    " \n",
    "#### Note that, for reference, you can look up the details of the relevant Spark methods in [Spark's Python API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) and the relevant NumPy methods in the [NumPy Reference](http://docs.scipy.org/doc/numpy/reference/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labVersion = 'cs190_week3_v_1_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Part 1: Read and parse the initial dataset **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1a) Load and check the data **\n",
    "#### The raw data is currently stored in text file.  We will start by storing this raw data in as an RDD, with each element of the RDD representing a data point as a comma-delimited string. Each string starts with the label (a year) followed by numerical audio features. Use the [count method](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.count) to check how many data points we have.  Then use the [take method](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.take) to create and print out a list of the first 5 data points in their initial string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
