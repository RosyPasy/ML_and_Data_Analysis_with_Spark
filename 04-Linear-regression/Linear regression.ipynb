{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ML Logo](http://spark-mooc.github.io/web-assets/images/CS190.1x_Banner_300.png)\n",
    "# **Linear Regression Lab**\n",
    "#### This lab covers a common supervised learning pipeline, using a subset of the [Million Song Dataset](http://labrosa.ee.columbia.edu/millionsong/) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD). Our goal is to train a linear regression model to predict the release year of a song given a set of audio features.\n",
    "#### ** This lab will cover: **\n",
    "+  ####*Part 1:* Read and parse the initial dataset\n",
    " + #### *Visualization 1:* Features\n",
    " + #### *Visualization 2:* Shifting labels\n",
    "+  ####*Part 2:* Create and evaluate a baseline model\n",
    " + #### *Visualization 3:* Predicted vs. actual\n",
    "+  ####*Part 3:* Train (via gradient descent) and evaluate a linear regression model\n",
    " + #### *Visualization 4:* Training error\n",
    "+  ####*Part 4:* Train using MLlib and tune hyperparameters via grid search\n",
    " + #### *Visualization 5:* Best model's predictions\n",
    " + #### *Visualization 6:* Hyperparameter heat map\n",
    "+  ####*Part 5:* Add interactions between features\n",
    " \n",
    "#### Note that, for reference, you can look up the details of the relevant Spark methods in [Spark's Python API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) and the relevant NumPy methods in the [NumPy Reference](http://docs.scipy.org/doc/numpy/reference/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labVersion = 'cs190_week3_v_1_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Part 1: Read and parse the initial dataset **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1a) Load and check the data **\n",
    "#### The raw data is currently stored in text file.  We will start by storing this raw data in as an RDD, with each element of the RDD representing a data point as a comma-delimited string. Each string starts with the label (a year) followed by numerical audio features. Use the [count method](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.count) to check how many data points we have.  Then use the [take method](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.take) to create and print out a list of the first 5 data points in their initial string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load testing library\n",
    "from test_helper import Test\n",
    "import os.path\n",
    "baseDir = os.path.join('data')\n",
    "inputPath = os.path.join('cs190', 'millionsong.txt')\n",
    "fileName = os.path.join(baseDir, inputPath)\n",
    "\n",
    "numPartitions = 2\n",
    "rawData = sc.textFile(fileName, numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6724\n",
      "[u'2001.0,0.884123733793,0.610454259079,0.600498416968,0.474669212493,0.247232680947,0.357306088914,0.344136412234,0.339641227335,0.600858840135,0.425704689024,0.60491501652,0.419193351817', u'2001.0,0.854411946129,0.604124786151,0.593634078776,0.495885413963,0.266307830936,0.261472105188,0.506387076327,0.464453565511,0.665798573683,0.542968988766,0.58044428577,0.445219373624', u'2001.0,0.908982970575,0.632063159227,0.557428975183,0.498263761394,0.276396052336,0.312809861625,0.448530069406,0.448674249968,0.649791323916,0.489868662682,0.591908113534,0.4500023818', u'2001.0,0.842525219898,0.561826888508,0.508715259692,0.443531142139,0.296733836002,0.250213568176,0.488540873206,0.360508747659,0.575435243185,0.361005878554,0.678378718617,0.409036786173', u'2001.0,0.909303285534,0.653607720915,0.585580794716,0.473250503005,0.251417011835,0.326976795524,0.40432273022,0.371154511756,0.629401917965,0.482243251755,0.566901413923,0.463373691946']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "#numPoints = <FILL IN>\n",
    "numPoints = rawData.count()\n",
    "print numPoints\n",
    "samplePoints = rawData.take(5)\n",
    "print samplePoints\n",
    "print len(rawData.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Load and check the data (1a)\n",
    "Test.assertEquals(numPoints, 6724, 'incorrect value for numPoints')\n",
    "Test.assertEquals(len(samplePoints), 5, 'incorrect length for samplePoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1b) Using `LabeledPoint` **\n",
    "#### In MLlib, labeled training instances are stored using the [LabeledPoint](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint) object.  Write the parsePoint function that takes as input a raw data point, parses it using Python's [unicode.split](https://docs.python.org/2/library/string.html#string.split) method, and returns a `LabeledPoint`.  Use this function to parse samplePoints (from the previous question).  Then print out the features and label for the first training point, using the `LabeledPoint.features` and `LabeledPoint.label` attributes. Finally, calculate the number features for this dataset.\n",
    "#### Note that `split()` can be called directly on a `unicode` or `str` object.  For example, `u'split,me'.split(',')` returns `[u'split', u'me']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "\n",
    "# Here is a sample raw data point:\n",
    "# '2001.0,0.884,0.610,0.600,0.474,0.247,0.357,0.344,0.33,0.600,0.425,0.60,0.419'\n",
    "# In this raw data point, 2001.0 is the label, and the remaining values are features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.884123733793,0.610454259079,0.600498416968,0.474669212493,0.247232680947,0.357306088914,0.344136412234,0.339641227335,0.600858840135,0.425704689024,0.60491501652,0.419193351817] 2001.0\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def parsePoint(line):\n",
    "    \n",
    "    \"\"\"Converts a comma separated unicode string into a `LabeledPoint`.\n",
    "\n",
    "    Args:\n",
    "        line (unicode): Comma separated unicode string where the first element is the label and the\n",
    "            remaining elements are features.\n",
    "\n",
    "    Returns:\n",
    "        LabeledPoint: The line is converted into a `LabeledPoint`, which consists of a label and\n",
    "            features.\n",
    "    \"\"\"\n",
    "    \n",
    "    aux = line.split(',')\n",
    "    aux = [float(i) for i in aux]\n",
    "    \n",
    "    #print aux[0]\n",
    "    #print aux[1:]\n",
    "    Label_Feature =  LabeledPoint(aux[0],aux[1:])\n",
    "    \n",
    "    #print Label_Feature.label\n",
    "    #print Label_Feature.features\n",
    "   \n",
    "        \n",
    "    return Label_Feature\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parsedSamplePoints = map(parsePoint,rawData.take(1))\n",
    "#print parsedSamplePoints[0].features\n",
    "firstPointFeatures = parsedSamplePoints[0].features\n",
    "firstPointLabel = parsedSamplePoints[0].label\n",
    "print firstPointFeatures, firstPointLabel\n",
    "\n",
    "d = len(firstPointFeatures)\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Using LabeledPoint (1b)\n",
    "Test.assertTrue(isinstance(firstPointLabel, float), 'label must be a float')\n",
    "expectedX0 = [0.8841,0.6105,0.6005,0.4747,0.2472,0.3573,0.3441,0.3396,0.6009,0.4257,0.6049,0.4192]\n",
    "Test.assertTrue(np.allclose(expectedX0, firstPointFeatures, 1e-4, 1e-4),\n",
    "                'incorrect features for firstPointFeatures')\n",
    "Test.assertTrue(np.allclose(2001.0, firstPointLabel), 'incorrect label for firstPointLabel')\n",
    "Test.assertTrue(d == 12, 'incorrect number of features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visualization 1: Features**\n",
    "#### First we will load and setup the visualization library.  Then we will look at the raw features for 50 data points by generating a heatmap that visualizes each feature on a grey-scale and shows the variation of each feature across the 50 sample data points.  The features are all between 0 and 1, with values closer to 1 represented via darker shades of grey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApsAAAJsCAYAAACyBWjFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nX1+v